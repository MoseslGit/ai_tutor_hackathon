{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\moses\\anaconda3\\envs\\ml_audio\\lib\\site-packages\\sacremoses-0.0.43-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install -q fsrs_optimizer==4.18.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moses\\anaconda3\\envs\\ml_audio\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fsrs_optimizer import lineToTensor, FSRS\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# Necessary Input:\n",
    "# z_score - only for questions that have been asked\n",
    "# asked questions to put into scheduler\n",
    "\n",
    "# parameters for FSRS\n",
    "w = [1.1008, 1.2746, 5.7619, 10.5114, 5.3148, 1.5796, 1.244, 0.003, 1.5741, 0.1741, 1.0137, 2.7279, 0.0114, 0.3071, 0.3981, 0.0, 1.9569]\n",
    "requestRetention = 0.82  # recommended setting: 0.8 ~ 0.9\n",
    "\n",
    "# parameters for Anki\n",
    "graduatingInterval = 1\n",
    "easyInterval = 4\n",
    "easyBonus = 1.3\n",
    "hardInterval = 1.2\n",
    "intervalModifier = 1\n",
    "newInterval = 0\n",
    "minimumInterval = 1\n",
    "leechThreshold = 8\n",
    "leechSuspend = False\n",
    "\n",
    "# common parameters\n",
    "maximumInterval = 36500\n",
    "new_cards_limits = 20\n",
    "review_limits = 400\n",
    "max_time_limts = 10000\n",
    "learn_days = 50\n",
    "\n",
    "# smooth curves\n",
    "moving_average_period = 14\n",
    "\n",
    "# Set it to True if you don't want the optimizer to use the review logs from suspended cards.\n",
    "filter_out_suspended_cards = False\n",
    "\n",
    "# Red: 1, Orange: 2, Green: 3, Blue: 4, Pink: 5, Turquoise: 6, Purple: 7\n",
    "# Set it to [1, 2] if you don't want the optimizer to use the review logs from cards with red or orange flag.\n",
    "filter_out_flags = []\n",
    "\n",
    "\n",
    "def get_schedule_scores(df, lesson_id):\n",
    "    '''Gets a df that contains id of question and schedule_scores for each one.\n",
    "    Input takes the full df and the lesson_id, or the number of days since the beginning of the course.\n",
    "    FSRS uses a calculated stability metric, which is how \"stable\" the idea is in your mind,\n",
    "    and schedules the next occurence of the card. We then scale this and normalize to give an output number\n",
    "    showing how urgent the card is, with 1 being the most urgent.\n",
    "    This is simply a time-series model with Markov property:\n",
    "    Depending on half-life, recall probability, result of recall, and difficulty, we define\n",
    "    a memory state-transition equation to update at every step.\n",
    "    We combine this with a Stochastic Shortest Path problem - the number of reviews required for memorizing something\n",
    "    to the require half-life is uncertain, so we combine the SSP and MMC to\n",
    "    find the optimal review time over iterations.'''\n",
    "    deck_size = len(df)\n",
    "    def calculate_review_duration(states, times):\n",
    "        if states[-1] != 2:\n",
    "            return 5\n",
    "        else:\n",
    "            # Find the most recent transition to state 2 from either 1 or 3\n",
    "            for i in range(len(states) - 1, 0, -1):\n",
    "                if states[i] == 2 and (states[i - 1] == 1 or states[i - 1] == 3):\n",
    "                    return times[i] - times[i - 1]\n",
    "            return 5  # Default value if no valid transition is found\n",
    "\n",
    "    # Apply the function to each row\n",
    "    df['review_duration'] = [calculate_review_duration(s, t) for s, t in zip(df['review_state'], df['review_time'])]\n",
    "\n",
    "    # Define the bins for the intervals\n",
    "    # bins = [0.25, 0.5, 0.75]\n",
    "    # df['z_score_last'] = df['z_scores'].apply(lambda x: x[-1] if isinstance(x, list) and x else np.nan)\n",
    "    # # Use numpy's digitize method to convert z_scores to review_rating\n",
    "    # df['review_rating'] = np.digitize(df['z_score_last'], bins) + 1\n",
    "    # df['review_rating'] = 5 - df['review_rating']\n",
    "\n",
    "    def assign_rating(row):\n",
    "        # Extract the last z_score value\n",
    "        z_score = row['z_scores'][-1] if isinstance(row['z_scores'], list) and row['z_scores'] else None\n",
    "        \n",
    "        # Assign ratings based on z_score\n",
    "        if z_score is not None:\n",
    "            if z_score <= 0.25:\n",
    "                return 1\n",
    "            elif z_score <= 0.5:\n",
    "                return 2\n",
    "            elif z_score <= 0.75:\n",
    "                return 3\n",
    "            else:\n",
    "                return 4\n",
    "        else:\n",
    "            return None  # or some default value\n",
    "    df['review_rating'] = df.apply(assign_rating, axis=1) \n",
    "    df['review_time_curr'] = df['review_time'].apply(lambda x: x[-1])\n",
    "    df['review_state_curr'] = df['review_state'].apply(lambda x: x[-1])\n",
    "    New = 0\n",
    "    Learning = 1\n",
    "    Review = 2\n",
    "    Relearning = 3\n",
    "\n",
    "    df.sort_values(by=[\"id\", \"review_time_curr\"], inplace=True, ignore_index=True)\n",
    "\n",
    "\n",
    "    recall_card_revlog = df[\n",
    "        (df[\"review_state_curr\"] == Review) & (df[\"review_rating\"].isin([2, 3, 4]))\n",
    "    ]\n",
    "    review_rating_prob = np.zeros(3)\n",
    "    review_rating_prob[recall_card_revlog[\"review_rating\"].value_counts().index - 2] = (\n",
    "        recall_card_revlog[\"review_rating\"].value_counts()\n",
    "        / recall_card_revlog[\"review_rating\"].count()\n",
    "    )\n",
    "    random_array = np.random.rand(4)\n",
    "    random_array /= random_array.sum()\n",
    "    first_rating_prob = random_array\n",
    "\n",
    "\n",
    "    df[\"review_state_curr\"] = df[\"review_state_curr\"].map(\n",
    "        lambda x: x if x != New else Learning)\n",
    "\n",
    "    recall_costs = np.zeros(3)\n",
    "    recall_costs_df = recall_card_revlog.groupby(by=\"review_rating\")[\n",
    "        \"review_duration\"\n",
    "    ].mean()\n",
    "    recall_costs[recall_costs_df.index - 2] = recall_costs_df / 1000\n",
    "\n",
    "    state_sequence = np.array(df[\"review_state_curr\"])\n",
    "    duration_sequence = np.array(df[\"review_duration\"])\n",
    "    learn_cost = round(\n",
    "        df[df[\"review_state_curr\"] == Learning][\"review_duration\"].sum()\n",
    "        / len(df[\"id\"].unique())\n",
    "        / 1000,\n",
    "        1,\n",
    "    )\n",
    "\n",
    "    state_block = dict()\n",
    "    state_count = dict()\n",
    "    state_duration = dict()\n",
    "    last_state = state_sequence[0]\n",
    "    state_block[last_state] = 1\n",
    "    state_count[last_state] = 1\n",
    "    state_duration[last_state] = duration_sequence[0]\n",
    "    for i, state in enumerate(state_sequence[1:]):\n",
    "        state_count[state] = state_count.setdefault(state, 0) + 1\n",
    "        state_duration[state] = state_duration.setdefault(\n",
    "            state, 0) + duration_sequence[i]\n",
    "        if state != last_state:\n",
    "            state_block[state] = state_block.setdefault(state, 0) + 1\n",
    "        last_state = state\n",
    "\n",
    "    recall_cost = round(state_duration[Review] / state_count[Review] / 1000, 1)\n",
    "\n",
    "    if Relearning in state_count and Relearning in state_block:\n",
    "        forget_cost = round(\n",
    "            state_duration[Relearning] /\n",
    "            state_block[Relearning] / 1000 + recall_cost,\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def generate_rating(review_type):\n",
    "        if review_type == \"new\":\n",
    "            return np.random.choice([1, 2, 3, 4], p=first_rating_prob)\n",
    "        elif review_type == \"recall\":\n",
    "            return np.random.choice([2, 3, 4], p=review_rating_prob)\n",
    "\n",
    "    class Collection:\n",
    "        def __init__(self):\n",
    "            self.model = FSRS(w)\n",
    "            self.model.eval()\n",
    "\n",
    "        def states(self, t_history, r_history):\n",
    "            with torch.no_grad():\n",
    "                line_tensor = lineToTensor(\n",
    "                    list(zip([str(t_history)], [str(r_history)]))[0]\n",
    "                ).unsqueeze(1)\n",
    "                output_t = self.model(line_tensor)\n",
    "                return output_t[-1][0]\n",
    "\n",
    "        def next_states(self, states, t, r):\n",
    "            with torch.no_grad():\n",
    "                return self.model.step(torch.FloatTensor([[t, r]]), states.unsqueeze(0))[0]\n",
    "\n",
    "        def init(self, idx):\n",
    "            t = df[\"review_time_curr\"][idx]\n",
    "            r = df[\"review_rating\"][idx]\n",
    "            p = round(first_rating_prob[r - 1], 2)\n",
    "            new_states = self.states(t, r)\n",
    "            return r, t, p, new_states\n",
    "\n",
    "\n",
    "    feature_list = [\n",
    "        \"id\",\n",
    "        \"difficulty\",\n",
    "        \"stability\",\n",
    "        \"retrievability\",\n",
    "        \"delta_t\",\n",
    "        \"reps\",\n",
    "        \"lapses\",\n",
    "        \"last_date\",\n",
    "        \"due\",\n",
    "        \"r_history\",\n",
    "        \"t_history\",\n",
    "        \"p_history\",\n",
    "        \"states\",\n",
    "        \"time\",\n",
    "        \"factor\",\n",
    "    ]\n",
    "    field_map = {key: i for i, key in enumerate(feature_list)}\n",
    "\n",
    "\n",
    "    def fsrs4anki_scheduler(stability):\n",
    "        def constrain_interval(stability):\n",
    "            if stability > 0:\n",
    "                return min(\n",
    "                    max(1, round(9 * stability * (1 / requestRetention - 1))),\n",
    "                    maximumInterval,\n",
    "                )\n",
    "            else:\n",
    "                return 1\n",
    "\n",
    "        interval = constrain_interval(stability)\n",
    "        return interval\n",
    "\n",
    "\n",
    "    def scheduler(fsrs_inputs):\n",
    "            return fsrs4anki_scheduler(fsrs_inputs), 2.5\n",
    "\n",
    "    #for scheduler_name in (\"anki\", \"fsrs\"):\n",
    "    for scheduler_name in [\"fsrs\"]:\n",
    "        new_card_per_day = np.array([0] * learn_days)\n",
    "        new_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "        review_card_per_day = np.array([0.0] * learn_days)\n",
    "        review_card_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "        time_per_day = np.array([0.0] * learn_days)\n",
    "        time_per_day_average_per_period = np.array([0.0] * learn_days)\n",
    "        learned_per_day = np.array([0.0] * learn_days)\n",
    "        retention_per_day = np.array([0.0] * learn_days)\n",
    "        expected_memorization_per_day = np.array([0.0] * learn_days)\n",
    "\n",
    "        card = pd.DataFrame(\n",
    "            np.zeros((deck_size, len(feature_list))),\n",
    "            index=range(deck_size),\n",
    "            columns=feature_list,\n",
    "        )\n",
    "        card[\"id\"] = df[\"id\"]\n",
    "        card[\"states\"] = card[\"states\"].astype(object)\n",
    "        card['reps'] = df['review_state'].apply(lambda x: len(x))\n",
    "        card[\"lapses\"] = 0\n",
    "        card[\"due\"] = learn_days\n",
    "        card[\"last_date\"] = df[\"review_time\"].apply(lambda x: x[-1])\n",
    "        \n",
    "        student = Collection()\n",
    "        random.seed(2022)\n",
    "        # do 1 step:\n",
    "        day = lesson_id\n",
    "        reviewed = 0\n",
    "        learned = 0\n",
    "        review_time_today = 0\n",
    "        learn_time_today = 0\n",
    "\n",
    "        card[\"delta_t\"] = day - card[\"last_date\"]\n",
    "        card[\"retrievability\"] = np.power(\n",
    "            1 + card[\"delta_t\"] / (9 * card[\"stability\"]), -1\n",
    "        )\n",
    "        need_learn = card[card[\"stability\"] == 0]\n",
    "\n",
    "        for idx in need_learn.index:\n",
    "            if (\n",
    "                learned >= new_cards_limits\n",
    "                or review_time_today + learn_time_today >= max_time_limts\n",
    "            ):\n",
    "                break\n",
    "            learned += 1\n",
    "            learn_time_today += learn_cost\n",
    "            #card.iat[idx, field_map[\"last_date\"]] = day\n",
    "\n",
    "            #card.iat[idx, field_map[\"reps\"]] = 1\n",
    "            #card.iat[idx, field_map[\"lapses\"]] = 0\n",
    "\n",
    "            r, t, p, new_states = student.init(idx)\n",
    "            new_stability = float(new_states[0])\n",
    "            new_difficulty = float(new_states[1])\n",
    "            card['r_history'] = card['r_history'].astype(object)\n",
    "            card['t_history'] = card['t_history'].astype(object)\n",
    "            card['p_history'] = card['p_history'].astype(object)\n",
    "            card.iat[idx, field_map[\"r_history\"]] = str(r)\n",
    "            card.iat[idx, field_map[\"t_history\"]] = str(t)\n",
    "            card.iat[idx, field_map[\"p_history\"]] = str(p)\n",
    "            card.iat[idx, field_map[\"stability\"]] = new_stability\n",
    "            card.iat[idx, field_map[\"difficulty\"]] = new_difficulty\n",
    "            card.iat[idx, field_map[\"states\"]] = new_states\n",
    "\n",
    "            delta_t, factor = scheduler(new_stability)\n",
    "            card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "            #card.iat[idx, field_map[\"due\"]] = day + delta_t\n",
    "            card.iat[idx, field_map[\"factor\"]] = factor\n",
    "\n",
    "            card.iat[idx, field_map[\"time\"]] = learn_cost\n",
    "\n",
    "\n",
    "        new_card_per_day[day] = learned\n",
    "        review_card_per_day[day] = reviewed\n",
    "        learned_per_day[day] = learned_per_day[day - 1] + learned\n",
    "        time_per_day[day] = review_time_today + learn_time_today\n",
    "        expected_memorization_per_day[day] = sum(\n",
    "            card[card[\"retrievability\"] > 0][\"retrievability\"]\n",
    "        )\n",
    "\n",
    "        if day >= moving_average_period:\n",
    "            new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                new_card_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "            review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                review_card_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "            time_per_day_average_per_period[day] = np.true_divide(\n",
    "                time_per_day[day - moving_average_period: day].sum(),\n",
    "                moving_average_period,\n",
    "            )\n",
    "        else:\n",
    "            new_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                new_card_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "            review_card_per_day_average_per_period[day] = np.true_divide(\n",
    "                review_card_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "            time_per_day_average_per_period[day] = np.true_divide(\n",
    "                time_per_day[: day + 1].sum(), day + 1\n",
    "            )\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    card['schedule_score'] = scaler.fit_transform(card[['due']])\n",
    "\n",
    "    # Inverting the values so that lower 'due' values are closer to 1\n",
    "    card['schedule_score'] = 1 - card['schedule_score']\n",
    "\n",
    "    # Returning the DataFrame with 'id' and 'schedule_score'\n",
    "    result = card[['id', 'schedule_score']]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>_category</th>\n",
       "      <th>embedding</th>\n",
       "      <th>review_state</th>\n",
       "      <th>review_time</th>\n",
       "      <th>z_scores</th>\n",
       "      <th>s_score</th>\n",
       "      <th>Q_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sumita Khatri wrote a research report and foll...</td>\n",
       "      <td>[No., Yes, relating to performance presentatio...</td>\n",
       "      <td>Ethical and Professional Standards</td>\n",
       "      <td>[0.007968312129378319, -0.0021401941776275635,...</td>\n",
       "      <td>[0, 1, 2, 3, 2, 3, 2, 3, 2, 3, 2]</td>\n",
       "      <td>[15, 27, 14, 27, 9, 29, 25, 17, 21, 27, 10]</td>\n",
       "      <td>[0.3820518737576567, 0.5363807206058436, 0.843...</td>\n",
       "      <td>0.610634</td>\n",
       "      <td>0.068177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aryana Reid, CFA, is a private wealth manager....</td>\n",
       "      <td>[Publish the post and send it as a mail to the...</td>\n",
       "      <td>Ethical and Professional Standards</td>\n",
       "      <td>[-0.02464733086526394, -0.014164824038743973, ...</td>\n",
       "      <td>[0, 1, 2, 3, 2, 3]</td>\n",
       "      <td>[12, 11, 19, 15, 10, 29]</td>\n",
       "      <td>[0.7689862117474828, 0.786084508687689, 0.2121...</td>\n",
       "      <td>0.296293</td>\n",
       "      <td>0.873316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kent Miller is an investment adviser at UBN In...</td>\n",
       "      <td>[determine Hartford’s needs, objectives, and t...</td>\n",
       "      <td>Ethical and Professional Standards</td>\n",
       "      <td>[-0.0013949209824204445, -0.01329685840755701,...</td>\n",
       "      <td>[0, 1, 2, 3, 2, 3, 2, 3, 2]</td>\n",
       "      <td>[21, 17, 10, 14, 9, 4, 1, 25, 22]</td>\n",
       "      <td>[0.870843353639129, 0.2345210061401538, 0.3750...</td>\n",
       "      <td>0.962313</td>\n",
       "      <td>0.997442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Justin Zoghlin, CFA, was hired as a wealth man...</td>\n",
       "      <td>[Serving the religious community., Managing no...</td>\n",
       "      <td>Ethical and Professional Standards</td>\n",
       "      <td>[-0.01206973847001791, -0.030683474615216255, ...</td>\n",
       "      <td>[0, 1, 2, 3, 2, 3, 2, 3, 2]</td>\n",
       "      <td>[11, 1, 18, 10, 8, 15, 27, 3, 8]</td>\n",
       "      <td>[0.4614002670673235, 0.35638086787218004, 0.90...</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.984961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rani Kaporwala, CFA, an analyst at Smart Secur...</td>\n",
       "      <td>[No., Yes, relating to communications with cli...</td>\n",
       "      <td>Ethical and Professional Standards</td>\n",
       "      <td>[0.016661042347550392, -0.013284368440508842, ...</td>\n",
       "      <td>[0, 1, 2, 3, 2, 3, 2, 3, 2]</td>\n",
       "      <td>[19, 19, 29, 22, 4, 21, 25, 10, 19]</td>\n",
       "      <td>[0.16358718871336497, 0.010827304568776674, 0....</td>\n",
       "      <td>0.635618</td>\n",
       "      <td>0.141168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   0  Sumita Khatri wrote a research report and foll...   \n",
       "1   1  Aryana Reid, CFA, is a private wealth manager....   \n",
       "2   2  Kent Miller is an investment adviser at UBN In...   \n",
       "3   3  Justin Zoghlin, CFA, was hired as a wealth man...   \n",
       "4   4  Rani Kaporwala, CFA, an analyst at Smart Secur...   \n",
       "\n",
       "                                             options  \\\n",
       "0  [No., Yes, relating to performance presentatio...   \n",
       "1  [Publish the post and send it as a mail to the...   \n",
       "2  [determine Hartford’s needs, objectives, and t...   \n",
       "3  [Serving the religious community., Managing no...   \n",
       "4  [No., Yes, relating to communications with cli...   \n",
       "\n",
       "                            _category  \\\n",
       "0  Ethical and Professional Standards   \n",
       "1  Ethical and Professional Standards   \n",
       "2  Ethical and Professional Standards   \n",
       "3  Ethical and Professional Standards   \n",
       "4  Ethical and Professional Standards   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.007968312129378319, -0.0021401941776275635,...   \n",
       "1  [-0.02464733086526394, -0.014164824038743973, ...   \n",
       "2  [-0.0013949209824204445, -0.01329685840755701,...   \n",
       "3  [-0.01206973847001791, -0.030683474615216255, ...   \n",
       "4  [0.016661042347550392, -0.013284368440508842, ...   \n",
       "\n",
       "                        review_state  \\\n",
       "0  [0, 1, 2, 3, 2, 3, 2, 3, 2, 3, 2]   \n",
       "1                 [0, 1, 2, 3, 2, 3]   \n",
       "2        [0, 1, 2, 3, 2, 3, 2, 3, 2]   \n",
       "3        [0, 1, 2, 3, 2, 3, 2, 3, 2]   \n",
       "4        [0, 1, 2, 3, 2, 3, 2, 3, 2]   \n",
       "\n",
       "                                   review_time  \\\n",
       "0  [15, 27, 14, 27, 9, 29, 25, 17, 21, 27, 10]   \n",
       "1                     [12, 11, 19, 15, 10, 29]   \n",
       "2            [21, 17, 10, 14, 9, 4, 1, 25, 22]   \n",
       "3             [11, 1, 18, 10, 8, 15, 27, 3, 8]   \n",
       "4          [19, 19, 29, 22, 4, 21, 25, 10, 19]   \n",
       "\n",
       "                                            z_scores   s_score   Q_score  \n",
       "0  [0.3820518737576567, 0.5363807206058436, 0.843...  0.610634  0.068177  \n",
       "1  [0.7689862117474828, 0.786084508687689, 0.2121...  0.296293  0.873316  \n",
       "2  [0.870843353639129, 0.2345210061401538, 0.3750...  0.962313  0.997442  \n",
       "3  [0.4614002670673235, 0.35638086787218004, 0.90...  0.036187  0.984961  \n",
       "4  [0.16358718871336497, 0.010827304568776674, 0....  0.635618  0.141168  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data_full.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_schedule_scores(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  schedule_score\n",
      "0    0    8.125000e-01\n",
      "1    1    8.125000e-01\n",
      "2    2    1.000000e+00\n",
      "3    3    9.791667e-01\n",
      "4    4    1.000000e+00\n",
      "5    5    6.041667e-01\n",
      "6    6    1.000000e+00\n",
      "7    7    1.000000e+00\n",
      "8    8    8.125000e-01\n",
      "9    9    6.041667e-01\n",
      "10  10    8.125000e-01\n",
      "11  11    1.000000e+00\n",
      "12  12    6.041667e-01\n",
      "13  13    8.125000e-01\n",
      "14  14    1.000000e+00\n",
      "15  15    8.125000e-01\n",
      "16  16    9.791667e-01\n",
      "17  17    8.125000e-01\n",
      "18  18    9.791667e-01\n",
      "19  19    8.125000e-01\n",
      "20  20    1.110223e-16\n",
      "21  21    1.110223e-16\n",
      "22  22    1.110223e-16\n",
      "23  23    1.110223e-16\n",
      "24  24    1.110223e-16\n",
      "25  25    1.110223e-16\n",
      "26  26    1.110223e-16\n",
      "27  27    1.110223e-16\n",
      "28  28    1.110223e-16\n",
      "29  29    1.110223e-16\n",
      "30  30    1.110223e-16\n",
      "31  31    1.110223e-16\n",
      "32  32    1.110223e-16\n",
      "33  33    1.110223e-16\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
